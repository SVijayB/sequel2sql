# SEQUEL2SQL Benchmark

A clean, user-friendly console application for running the BIRD-CRITIC PostgreSQL benchmark (531 queries) using Google Gemma 3 27B with intelligent API key rotation and full Docker-based evaluation.

## Features

- ğŸš€ **PostgreSQL Focus**: 531 real-world SQL debugging queries
- ğŸ¤– **Gemma 3 27B**: Google's latest AI model for SQL generation  
- ğŸ”„ **Smart API Key Rotation**: Automatic cycling through 8 API keys with rate limit handling
- ğŸ“Š **Progress Tracking**: Real-time progress bars with statistics
- ğŸ’¾ **Resume Capability**: Checkpoint every 10 queries to resume interrupted runs
- ğŸ³ **Docker Evaluation**: Full PostgreSQL database validation
- ğŸ“ **Dual Logging**: Console output + detailed file logs

## Quick Start

### 1. Setup Environment

```bash
# Navigate to benchmark directory
cd /home/svijayb/sequel2sql/benchmark

# Create .env file with your API keys
cp ../.env.example ../.env

# Edit .env and add your 8 Gemini API keys
# Get keys from: https://ai.google.dev/
nano ../.env
```

Your `.env` should look like:
```bash
GEMINI_API_KEY_1=AIza...your_key_1
GEMINI_API_KEY_2=AIza...your_key_2
# ... (8 keys total)
```

### 2. Install Dependencies

Dependencies are already installed at the repository root via UV. If you need to reinstall:

```bash
cd /home/svijayb/sequel2sql
uv add python-dotenv rich tqdm psycopg2-binary pyfiglet google-generativeai
```

### 3. Start Docker

Make sure Docker is running:
```bash
# Check Docker status
docker ps

# On Linux, if Docker isn't running:
sudo systemctl start docker

# On Mac/Windows: Start Docker Desktop
```

### 4. Run Benchmark

```bash
cd /home/svijayb/sequel2sql
./benchmark.sh
```

The benchmark supports two modes:

**Interactive Mode** (recommended for first-time users):
```bash
./benchmark.sh
# You'll be prompted:
# 1. Do you want to run a subset? [y/N]
# 2. If yes, how many queries? [default: 20]
```

**Command-Line Mode** (for automation):
```bash
# Test with 20 queries
./benchmark.sh --limit 20

# Test with 100 queries
./benchmark.sh --limit 100

# Run all 531 queries
./benchmark.sh
```

ğŸ“– **See [TESTING_GUIDE.md](../TESTING_GUIDE.md) for detailed testing workflows and recommendations.**

The benchmark will:
1. Display the SEQUEL2SQL logo and configuration
2. Ask how many queries to run (or use --limit)
3. Generate prompts for your selected queries
4. Call Gemma 3 27B with intelligent key rotation
5. Extract SQL from responses
6. Start Docker containers
7. Run evaluation against PostgreSQL
8. Display comprehensive results

## Testing Recommendations

Before running the full 531-query benchmark (~5-6 hours), **start with a small subset**:

1. **Quick Test** (5-10 queries): `./benchmark.sh --limit 10` â†’ ~10 minutes
2. **Small Test** (20-50 queries): `./benchmark.sh --limit 20` â†’ ~30 minutes
3. **Medium Test** (100 queries): `./benchmark.sh --limit 100` â†’ ~1-2 hours
4. **Full Benchmark** (531 queries): `./benchmark.sh` â†’ ~5-6 hours

See [TESTING_GUIDE.md](../TESTING_GUIDE.md) for complete testing workflow.

## Usage Examples

### Testing with Subset (Interactive)

```bash
$ ./benchmark.sh

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   SEQUEL2SQL                              â•‘
â•‘              BENCHMARK EVALUATION SYSTEM                  â•‘
â•‘     PostgreSQL SQL Generation Benchmark using Gemma 3     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Query Selection                   â”‚
â”‚                                            â”‚
â”‚  Total available queries: 531              â”‚
â”‚                                            â”‚
â”‚  You can either run all queries or test   â”‚
â”‚  with a subset.                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Do you want to run a subset (for testing)? [y/N]: y
How many queries do you want to run? (1-531) [20]: 20
âœ“ Running subset of 20 queries

Configuration:
  â€¢ Dialect:       PostgreSQL 14.12
  â€¢ Model:         Google Gemma 3 27B
  â€¢ Total Queries: 20              â† Updated!
  â€¢ API Keys:      8 configured
  â€¢ Threads:       8 workers

Run benchmark? (y/n): y
```

### Resume Interrupted Run

If your run gets interrupted, just run `./benchmark.sh` again:

```bash
$ ./run.sh

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           PREVIOUS RUN DETECTED                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Progress: 245/531 queries completed (46.14%)             â•‘
â•‘  Options: [Y] Resume  [R] Restart  [N] Exit               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Your choice: resume
```

## Output Structure

Each run creates a timestamped directory:

```
benchmark/
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ run_2026-02-02_14-30-45/
â”‚       â”œâ”€â”€ prompts.jsonl              # Generated prompts
â”‚       â”œâ”€â”€ responses.jsonl            # Raw LLM responses
â”‚       â”œâ”€â”€ checkpoint.json            # Progress checkpoint
â”‚       â”œâ”€â”€ final_output.jsonl         # Extracted SQL
â”‚       â””â”€â”€ final_output_report.txt    # Evaluation results
â”‚
â””â”€â”€ logs/
    â””â”€â”€ benchmark_2026-02-02_14-30-45.log  # Detailed logs
```

## Configuration

All configuration is in [src/config.py](src/config.py):

```python
MODEL_CONFIG = {
    "model_name": "models/gemma-3-27b-it",
    "temperature": 0.0,
    "max_tokens": 2048,
    "timeout": 10,
    "max_threads": 8,
    "checkpoint_frequency": 10
}
```

Modify these values if needed (e.g., increase `max_threads` for faster processing).

## Troubleshooting

### Issue: "âŒ Error: .env file not found"

**Solution**: Create .env file at repository root:
```bash
cd /home/svijayb/sequel2sql
cp .env.example .env
# Edit .env and add your 8 API keys
```

### Issue: "âŒ Error: Docker is not running"

**Solution**:
```bash
# Linux
sudo systemctl start docker

# Mac/Windows
# Start Docker Desktop application
```

### Issue: "Failed to start Docker containers"

**Solution**:
```bash
# Check Docker logs
docker compose logs

# Rebuild containers
docker compose up -d --build

# If stuck, reset:
docker compose down
docker compose up -d --build
```

### Issue: API Rate Limits

**Solution**: This is expected! The system automatically:
1. Rotates through your 8 API keys
2. Waits 60 seconds when all keys are exhausted
3. Resumes with the first key

Make sure all 8 API keys are valid and have quota.

### Issue: Evaluation Fails

**Solution**:
```bash
# Check if PostgreSQL is healthy
docker exec sequel2sql_postgresql pg_isready -U root

# Check container status
docker ps

# View evaluation container logs
docker logs sequel2sql_eval

# Restart evaluation only (without re-running LLM):
# Just re-run ./run.sh and it will skip to evaluation phase
```

### Issue: Out of Memory

**Solution**:
1. Reduce `max_threads` in `src/config.py` (try 4 instead of 8)
2. Close other applications
3. Increase Docker memory limit (in Docker Desktop settings)

## Performance

### Expected Timing
- **Prompt Generation**: ~2-5 seconds
- **LLM Inference**: ~40-60 minutes (531 queries)
- **Post-processing**: ~2-5 seconds
- **Evaluation**: ~15-30 minutes
- **Total Runtime**: ~1-1.5 hours

### Speed Tips
1. Use all 8 API keys for best throughput
2. Increase `max_threads` if you have quota (e.g., 16)
3. Use SSD storage for faster Docker I/O
4. Run on a machine with good network connection

## Docker Containers

The benchmark uses two containers:

1. **sequel2sql_postgresql**: PostgreSQL 14.12 database server
   - Port: 5432
   - User: root
   - Password: 123123
   - Contains 15 template databases

2. **sequel2sql_eval**: Python evaluation environment
   - Runs test cases against generated SQL
   - Handles database isolation and cleanup

### Managing Containers

```bash
# Start containers
docker compose up -d

# Stop containers
docker compose down

# View logs
docker compose logs

# Restart containers
docker compose restart

# Remove everything (including data)
docker compose down -v
```

## Evaluation Metrics

The benchmark reports:

- **Overall Accuracy**: Percentage of queries that pass all test cases
- **Execution Errors**: SQL syntax or runtime errors
- **Timeout Errors**: Queries that exceed time limits
- **Assertion Errors**: Queries that produce wrong results

### Category Breakdown

- **Query** (~390 queries): SELECT statement issues
- **Management** (~105 queries): DDL/DML operations
- **Personalization** (~36 queries): Complex custom requirements

## Advanced Usage

### Test with Subset

To test with only 10 queries (faster):

```python
# Edit main.py, line 281:
num_generated = generate_prompts_from_file(
    data_file,
    prompts_file,
    schema_field="preprocess_schema",
    limit=10  # Add this line
)
```

### Retry Failed Queries

The checkpoint system tracks failed queries. To retry them:

```bash
# The system will automatically retry failed queries
# when you resume from a checkpoint
./run.sh
# Choose "resume"
```

### Clean Start

To clear everything and start fresh:

```bash
# Remove outputs and logs
rm -rf outputs/* logs/*

# Run benchmark
./run.sh
```

## Project Structure

```
benchmark/
â”œâ”€â”€ main.py                    # Main orchestrator
â”œâ”€â”€ run.sh                     # Launcher script
â”œâ”€â”€ docker-compose.yml         # Docker configuration
â”œâ”€â”€ IMPLEMENTATION.md          # Detailed implementation docs
â”œâ”€â”€ README.md                  # This file
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ config.py              # Configuration and .env loading
â”‚   â”œâ”€â”€ logger_config.py       # Logging setup
â”‚   â”œâ”€â”€ api_client.py          # Gemini API with key rotation
â”‚   â”œâ”€â”€ checkpoint_manager.py  # Save/resume functionality
â”‚   â”œâ”€â”€ ui.py                  # Terminal UI components
â”‚   â”œâ”€â”€ prompt_generator.py    # Prompt creation
â”‚   â”œâ”€â”€ inference_engine.py    # Multi-threaded LLM calls
â”‚   â”œâ”€â”€ post_processor.py      # SQL extraction
â”‚   â”œâ”€â”€ postgresql_utils.py    # Database utilities
â”‚   â”œâ”€â”€ wrapper_evaluation_postgresql.py    # Evaluation runner
â”‚   â””â”€â”€ single_instance_eval_postgresql.py  # Single query evaluation
â”‚
â”œâ”€â”€ data/                      # Input data
â”‚   â”œâ”€â”€ postgresql_full.jsonl # 531 queries
â”‚   â””â”€â”€ postgre_table_dumps/  # Database templates
â”‚
â”œâ”€â”€ env/                       # Docker build files
â”‚   â”œâ”€â”€ Dockerfile.postgresql
â”‚   â””â”€â”€ Dockerfile.so_eval
â”‚
â”œâ”€â”€ outputs/                   # Generated outputs (gitignored)
â””â”€â”€ logs/                      # Log files (gitignored)
```

## API Key Rotation

The system uses intelligent key rotation:

```
Request 1 â†’ Key 1
Request 2 â†’ Key 2
...
Request 8 â†’ Key 8
Request 9 â†’ Key 1  (back to start)

If all 8 keys hit rate limits:
  â±ï¸  Wait 60 seconds
  ğŸ”„ Resume with Key 1
```

### Getting API Keys

1. Go to https://ai.google.dev/
2. Sign in with Google account
3. Create API key
4. Repeat 8 times (you can use different Google accounts)
5. Add all keys to `.env`

## Contributing

This benchmark is part of the SEQUEL2SQL project. For detailed implementation information, see [IMPLEMENTATION.md](IMPLEMENTATION.md).

## References

- **BIRD-CRITIC**: https://github.com/bird-bench/BIRD-CRITIC-1
- **Google Gemini API**: https://ai.google.dev/docs
- **PostgreSQL 14**: https://www.postgresql.org/docs/14/

## License

See repository root for license information.

---

**Need Help?**

1. Check [IMPLEMENTATION.md](IMPLEMENTATION.md) for detailed technical docs
2. Review logs in `benchmark/logs/`
3. Check Docker logs: `docker compose logs`
4. Open an issue in the repository

Happy benchmarking! ğŸš€
